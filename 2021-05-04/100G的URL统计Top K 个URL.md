## 给定 100G 的 URL 磁盘数据，使用最多 1G 内存，统计出现频率最高的 Top K 个 URL
### 散列+分治+合并

- 散列分组：对100G的URL进行哈希（可以保证相同的URL分到同一个组），切分成多个组。由于内存最多只能放1G，所以至少要分成100组。这里分成200组，每次加载一组（散列均匀的情况下，每组平均512M）进行统计组内的Tok K；

- 处理：使用HashMap对小组内的URL统计频次，然后把\<URL，频次\>键值对放到小顶堆里排序，堆大小大于K时，弹出堆顶（频次最低的URL），维持堆的大小为K；200分组处理完之后，得到200个大小为K的小顶堆，即Top 200K个URL，并把他们保存到同一个数组里。

- 合并结果：对第二步得到的Top 200K个URL进行堆排序（根据具体场景其他排序也可以），依然是使用小顶堆，堆大小超过K就弹出堆顶元素，最终得到大小为K的堆，即为所有URL中Top K的URL。

### 特殊情况讨论
上述方案在第二步的处理中，需要 200K个URL大小 的空间保存分组处理的结果，由于内存限制为1G，1G / 200 = 5.12M，K个URL的大小不能超过5.12M。所以，这时候需要在分治过程中合并结果，具体如下（假设K个URL大小为64M）：

- 依然是散列分成200组，每组K个URL。
- 同上第二步，200URL每组内部进行堆排序去Top K。组内的K个URL缓存到数组中。由于K个URL大小为64M，那么内存一次只能处理 1G / 64M = 16 组URL。
- 因此每处理 16 组URL，需要对数组内的URL堆排序（依然是小堆顶取Top K）。循环以上过程13次即可处理完200组（16 * 13 = 208 > 200），得到的13个大小为K的小顶堆。
- 由上述计算可知，K个一组URL大小为64M时，内存最多可以存16组，那么13个小顶堆已经可以一次性放入内存中排序了，依然是小顶堆排序取Top K。即可得到所有数据的Top K。

### 总结
散列+分治+合并结果的方案，对于类似Top K问题都适用，但是需要注意一下亮点：

- 选择合适的散列算法，使数据分组尽量均匀，避免个别组撑爆有限的内存。
- K很大时，分治过程产生的中间结果会导致内存逐渐不足。因此需要在分治的过程中合并结果，具体需要多合并几次，如上述讨论，根据具体数字分析。